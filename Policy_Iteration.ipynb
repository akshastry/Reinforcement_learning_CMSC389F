{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week4",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/akshastry/Reinforcement_learning_CMSC389F/blob/master/Policy_Iteration.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "ylyYEPNEjS83",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "c8fe59a9-6b96-4ac0-c840-bf3fade9d82b"
      },
      "cell_type": "code",
      "source": [
        "!pip install gym\n",
        "!pip install scipy\n",
        "!pip install seaborn\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import gym\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "import sys\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from copy import deepcopy\n",
        "\n",
        "random.seed(0)\n",
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gym\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/50/ed4a03d2be47ffd043be2ee514f329ce45d98a30fe2d1b9c61dea5a9d861/gym-0.10.5.tar.gz (1.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.5MB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python2.7/dist-packages (from gym) (1.14.5)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python2.7/dist-packages (from gym) (2.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (from gym) (1.11.0)\n",
            "Collecting pyglet>=1.2.0 (from gym)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/fc/dad5eaaab68f0c21e2f906a94ddb98175662cc5a654eee404d59554ce0fa/pyglet-1.3.2-py2.py3-none-any.whl (1.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.0MB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.0->gym) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.0->gym) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.0->gym) (2018.8.24)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.0->gym) (3.0.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python2.7/dist-packages (from pyglet>=1.2.0->gym) (0.16.0)\n",
            "Building wheels for collected packages: gym\n",
            "  Running setup.py bdist_wheel for gym ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/cb/14/71/f4ab006b1e6ff75c2b54985c2f98d0644fffe9c1dddc670925\n",
            "Successfully built gym\n",
            "Installing collected packages: pyglet, gym\n",
            "Successfully installed gym-0.10.5 pyglet-1.3.2\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python2.7/dist-packages (0.19.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy) (1.14.5)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python2.7/dist-packages (0.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RxpRqF7lkTRo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create Environment"
      ]
    },
    {
      "metadata": {
        "id": "fRAv4JK0kf6d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gym.envs.registration import register\n",
        "register(\n",
        "    id='FrozenLakeNotSlippery-v0',\n",
        "    entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
        "    kwargs={'map_name' : '4x4', 'is_slippery': False},\n",
        "    max_episode_steps=100,\n",
        "    reward_threshold=0.78, \n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lxxHRsYeks6L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "4d8e7fec-6543-4df5-84f6-22d223a75c28"
      },
      "cell_type": "code",
      "source": [
        "env = gym.make('FrozenLakeNotSlippery-v0')\n",
        "print('action space: ', env.action_space)\n",
        "print('observation space: ', env.observation_space)\n",
        "env.render()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('action space: ', Discrete(4))\n",
            "('observation space: ', Discrete(16))\n",
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bXTDXZIPmn5r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Offline Planning (Policy Iteration)"
      ]
    },
    {
      "metadata": {
        "id": "Ca9sgLeEmq-e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class FrozenLake4x4:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.grid = [[0, 0, 0, 0],    # SFFF\n",
        "                    [0, -1, 0, -1],   # FHFH\n",
        "                    [0, 0, 0, -1],    # FFFH\n",
        "                    [-1, 0, 0, 1]]    # HFFG\n",
        "\n",
        "        self.m = len(self.grid)\n",
        "        self.n = len(self.grid[0])\n",
        "        \n",
        "        self.discount = 0.9\n",
        "        \n",
        "        self.values = [[0] * self.n for _ in range(self.m)]\n",
        "        self.values[self.m-1][self.n-1] = 1\n",
        "        \n",
        "        # Set up random policy\n",
        "        self.policy = [[{0, 1, 2, 3}] * self.n for _ in range(self.m)]\n",
        "        \n",
        "        #You can't have a policy for a terminal state\n",
        "        for i in range(self.m):\n",
        "            for j in range(self.n):\n",
        "                if self.grid[i][j] != 0:\n",
        "                    self.policy[i][j] = None\n",
        "                    \n",
        "\n",
        "\n",
        "    def _up(self, i, j):\n",
        "        if i == 0:\n",
        "            return i, j\n",
        "        else:\n",
        "            return i-1, j\n",
        "\n",
        "    def _right(self,i, j):\n",
        "        if j == self.n - 1:\n",
        "            return i, j\n",
        "        else:\n",
        "            return i, j+1\n",
        "\n",
        "    def _down(self, i, j):\n",
        "        if i == self.m - 1:\n",
        "            return i, j\n",
        "        else:\n",
        "            return i+1, j\n",
        "\n",
        "    def _left(self, i, j):\n",
        "        if j == 0:\n",
        "            return i, j\n",
        "        else:\n",
        "            return i, j-1\n",
        "\n",
        "    # Gives you the indices of the position you end up in given a position and a\n",
        "    # direction\n",
        "    # UP = 0\n",
        "    # DOWN = 1\n",
        "    # RIGHT = 2\n",
        "    # LEFT = 3\n",
        "    def move(self, i, j, d):\n",
        "        if d == 0:\n",
        "            i, j = self._up(i, j)\n",
        "        elif d == 1:\n",
        "            i, j = self._down(i, j)\n",
        "        elif d == 2:\n",
        "            i, j =  self._right(i, j)\n",
        "        else:\n",
        "            i, j = self._left(i, j)\n",
        "\n",
        "        return i, j\n",
        "    \n",
        "    # Get the value of a neighbor\n",
        "    def _value(self, i, j, d):\n",
        "        i, j = self.move(i, j, d)\n",
        "        return self.values[i][j]\n",
        "    \n",
        "    # Use to keep track of the highest attainable value\n",
        "    def _compare(self, mx, new, d, p):\n",
        "        if mx < new:\n",
        "            return (new, {d})\n",
        "        elif mx == new:\n",
        "            p.add(d)\n",
        "            return (mx, p)\n",
        "        else:\n",
        "            return (mx, p)\n",
        "        \n",
        "    def _iterate_policy(self):\n",
        "        new_values = deepcopy(self.values)\n",
        "        new_policy = deepcopy(self.policy)\n",
        "        \n",
        "        #TODO\n",
        "        #This code block should include \n",
        "        #Policy Evaluation\n",
        "        #Policy Update\n",
        "        #Check to see if policy changed\n",
        "        #If it did, return False\n",
        "        #If it didn't, return True\n",
        "        \n",
        "        \n",
        "        \n",
        "    def solve(self):\n",
        "        converge = False\n",
        "        while not converge:\n",
        "            converge = self._iterate_policy()\n",
        "        return self.policy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ahAM-0hk90i4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fl = FrozenLake4x4()\n",
        "fl.solve()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jBlmdbOoIE8W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Running the Agent"
      ]
    },
    {
      "metadata": {
        "id": "Xp7q-bT6IJei",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_episode():\n",
        "    obs = env.reset()\n",
        "    done = False\n",
        "    i, j = 0, 0\n",
        "    while not done:\n",
        "        env.render()\n",
        "        action = random.sample(fl.policy[i][j], 1)[0]\n",
        "        i, j = fl.move(i, j, action)\n",
        "        obs, reward, done, info = env.step(action)\n",
        "    \n",
        "    env.render()\n",
        "\n",
        "    \n",
        "run_episode()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Djk_Fhhc5Tpv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Assignment\n",
        "Due before class next week:\n",
        "\n",
        "See if you can adapt the above classes for policy iteration to solve the slippery (stochastic) version of frozen lake. You can directly copy and paste any code from above or the answer key for this lecture. If you're feeling ambitious, feel free to code your own take on it from scratch! \n",
        "\n",
        "To see a heatmap of state values, try running ```sns.heatmap(fl.values)``` \n",
        "\n",
        "You should also check out more things youcan do with seaborn at https://seaborn.pydata.org/ as we will be using it more in the future. "
      ]
    },
    {
      "metadata": {
        "id": "AWDE3Xty6mZ3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gym.envs.registration import register\n",
        "register(\n",
        "    id='FrozenLakeSlippery-v0',\n",
        "    entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
        "    kwargs={'map_name' : '4x4', 'is_slippery': True},\n",
        "    max_episode_steps=100,\n",
        "    reward_threshold=0.78, \n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-bSo12SU6xfC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "env = gym.make('FrozenLakeSlippery-v0')\n",
        "print('action space: ', env.action_space)\n",
        "print('observation space: ', env.observation_space)\n",
        "env.render()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}